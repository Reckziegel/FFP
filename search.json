[{"path":"/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to ffp","title":"Contributing to ffp","text":"outlines propose change ffp. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to ffp","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to ffp","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed).","code":""},{"path":"/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to ffp","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"Reckziegel/FFP\", fork = TRUE). Install development dependences devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to ffp","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to ffp","text":"Please note ffp project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 Bernardo Reckziegel Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/views.html","id":"views-on-expected-returns","dir":"Articles","previous_headings":"","what":"Views on Expected Returns","title":"Views","text":"Assume investor believes FTSE index return \\(20\\%\\) average near future. order process view, investor needs minimize relative entropy: \\[ \\sum_{j=1}^J x_j(ln(x_j) - ln(p_j)) \\] Subject restriction: \\[ \\ x_j V_{j, k} = \\mu_{k} \\] \\(x_{j}\\) yet discovered posterior probability; \\(V_{j,k}\\) \\(1859 \\times 1\\) vector FTSE returns; \\(\\mu_{k}\\) \\(1 \\times 1\\) scalar investor projected return FTSE index. case, \\(k\\) subscript represents fourth column x2. Views expected returns can constructed view_on_mean: views object list two components, Aeq beq, equivalent elements \\(V_{j,k}\\) transposed \\(\\mu_{k}\\), respectively. investor also needs formulate vector prior probabilities, \\(p_j\\), usually - necessary - equal-weight vector: prior views established, optimization can take place entropy_pooling: interpretation ep? Among possible probability vectors, ep one can satisfy views “least” evasive way (term “least evasive” direct reference prior). Therefore, ep best candidate posterior distribution. real world, investor can many views. Extending current example, say investor new belief: CAC index returns \\(10\\%\\) bellow average3: elements Aeq beq now \\(2\\) rows , one every view. minimum relative entropy problem solved exact way: ’s easier analyse output ep visually. end, autoplot method available objects ffp class:  plot reinforces intuition \\(x_j\\) - posterior probability - distribution distorts prior order accommodate views. ’s easy double-check investor views computing ratio conditional vs. unconditional returns: According expectations, CAC outlook now \\(10\\%\\) bellow average FTSE expected return \\(20\\%\\) average. Violà!","code":"# Returns 20% higher than average mu <- mean(x[ , \"FTSE\"]) * 1.2  # ffp views constructor views <- view_on_mean(x = as.matrix(x[ , \"FTSE\"]), mean = mu) views #> # ffp view #> Type:  View On Mean #> Aeq :  Dim 1 x 1859  #> beq :  Dim 1 x 1 # Prior probabilities p_j <- rep(1 / nrow(x), nrow(x)) # Solve Minimum Relative Entropy (MRE) ep <- entropy_pooling(   p      = p_j,    Aeq    = views$Aeq,    beq    = views$beq,    solver = \"nlminb\" ) ep #> <ffp[1859]> #> 0.0005425631 0.0005340012 0.000544236 0.0005418246 0.0005322989 ... 0.0005451271 mu <- c(   mean(x[ , \"FTSE\"]) * 1.2, # Return 20% higher than average   mean(x[ , \"CAC\"]) * 0.9   # Return 10% bellow average )  # ffp views constructor views <- view_on_mean(x = as.matrix(x[ , c(\"FTSE\", \"CAC\")]), mean = mu) views #> # ffp view #> Type:  View On Mean #> Aeq :  Dim 2 x 1859  #> beq :  Dim 2 x 1 # Solve MRE ep <- entropy_pooling(   p      = p_j,    Aeq    = views$Aeq,    beq    = views$beq,    solver = \"nlminb\" ) ep #> <ffp[1859]> #> 0.0005602371 0.0005473082 0.0005573006 0.0005384979 0.000531066 ... 0.0005434801 class(ep) #> [1] \"ffp\"        \"vctrs_vctr\" autoplot(ep) +    scale_color_viridis_c(option = \"C\", end = 0.75) +    labs(title    = \"Posterior Probability Distribution\",         subtitle = \"Views on Expected Returns\",         x        = NULL,         y        = NULL) conditional   <- ffp_moments(x, ep)$mu  unconditional <- colMeans(x)  conditional / unconditional - 1 #>         DAX         SMI         CAC        FTSE  #>  0.01335825  0.02078130 -0.09999999  0.20000009"},{"path":"/articles/views.html","id":"views-on-volatility","dir":"Articles","previous_headings":"","what":"Views on Volatility","title":"Views","text":"Say investor confident markets followed period lull bonanza. Without additional insights expected returns, investor anticipates market volatility CAC index drop \\(10\\%\\). impose views volatility, investor needs minimize expression: \\[ \\sum_{j=1}^J x_j(ln(x_j) - ln(p_j)) \\] Subject constraint: \\[ \\sum_{j=1}^{J} x_j V_{j, k}^2 = \\mu_{k}^2 + \\sigma_{k}^2 \\] , \\(x_j\\) vector yet defined posterior probabilities; \\(V_{j,k}^2\\) \\(1859 \\times 1\\) vector CAC squared returns; \\(\\mu_{k}^2\\) \\(\\sigma_{k}^2\\) CAC sample mean variance; \\(k\\) column position CAC panel \\(V\\). view_on_volatility function can used purpose: views object holds list two components - Aeq beq - equivalent elements \\(V_{j,k}^2\\) transposed \\(\\mu_{k}^2 + \\sigma_{k}^2\\), respectively. solve relative entropy use entropy_pooling function: , ep vector call posterior: probability vector causes “least” amount distortion prior, still obeys constraints (views). posterior probabilities can observed autoplot method:  check posterior probabilities valid way display investor’s view, compare conditional vs. unconditional volatilities: posterior volatility CAC index reduced \\(10\\%\\), line investor’s subjective judgment. However, emphasizing tranquil periods often, assets also affected, smaller magnitudes.","code":"# opinion vol_cond <- sd(x[ , \"CAC\"]) * 0.9  # views views <- view_on_volatility(x = as.matrix(x[ , \"CAC\"]), vol = vol_cond) views #> # ffp view #> Type:  View On Volatility #> Aeq :  Dim 1 x 1859  #> beq :  Dim 1 x 1 ep <- entropy_pooling(   p      = p_j,    Aeq    = views$Aeq,    beq    = views$beq,    solver = \"nlminb\" ) ep #> <ffp[1859]> #> 0.0005227495 0.0004701207 0.0005609239 0.0005476659 0.0005631671 ... 0.0005349393 autoplot(ep) +    scale_color_viridis_c(option = \"C\", end = 0.75) +    labs(title    = \"Posterior Probability Distribution\",         subtitle = \"View on Volatility\",         x        = NULL,         y        = NULL) unconditional <- apply(x, 2, sd) conditional   <- sqrt(diag(ffp_moments(x, ep)$sigma))  conditional / unconditional - 1 #>         DAX         SMI         CAC        FTSE  #> -0.08377407 -0.06701178 -0.09977906 -0.04552477"},{"path":"/articles/views.html","id":"views-on-correlation","dir":"Articles","previous_headings":"","what":"Views on Correlation","title":"Views","text":"Assume investor believes correlation FTSE DAX increase \\(30\\%\\), \\(0.64\\) \\(0.83\\). construct views correlation matrix, general expression minimized: \\[ \\sum_{j=1}^J x_j(ln(x_j) - ln(p_j)) \\] Subject constraints: \\[ \\sum_{j=1}^{J} x_j V_{j, k} V_{j, l} = \\mu_{k} \\mu_{l} + \\sigma_{k} \\sigma_{l} C_{k,l} \\] , term \\(V_{j, k} V_{j, l}\\) left hand-side restriction consists cross-correlations among assets; terms \\(\\mu_{k} \\mu_{l} + \\sigma_{k} \\sigma_{l} C_{k,l}\\) carry investor target correlation structure; \\(x_j\\) yet defined probability vector. formulate view, first compute unconditional correlation matrix. Second, add “perturbation” corresponding element consistent perceived view: Finally, pass adjusted correlation matrix view_on_correlation function: Aeq equal \\(V_{j, k} V_{j, l}\\) transposed beq \\(10 \\times 1\\) vector \\(\\mu_{k} \\mu_{l} + \\sigma_{k} \\sigma_{l} C_{k,l}\\). Notice even though investor view just one parameter4 constraint vector \\(10\\) rows, every element lower/upper diagonal correlation matrix match. , minimum entropy solved entropy_pooling: autoplot method available:  fact-check investor view, compute posterior correlation matrix: notice linear association FTSE DAX now \\(0.83\\)!","code":"cor_view <- cor(x) # unconditional correlation matrix cor_view[\"FTSE\", \"DAX\"] <- 0.83 # perturbation (investor belief) cor_view[\"DAX\", \"FTSE\"] <- 0.83 # perturbation (investor belief) views <- view_on_correlation(x = x, cor = cor_view) views #> # ffp view #> Type:  View On Correlation #> Aeq :  Dim 10 x 1859  #> beq :  Dim 10 x 1 ep <- entropy_pooling(   p      = p_j,    Aeq    = views$Aeq,    beq    = views$beq,    solver = \"nlminb\" ) ep #> <ffp[1859]> #> 6.709143e-05 0.000659403 0.001085763 0.0003254822 0.0005215729 ... 0.0004748052 autoplot(ep) +    scale_color_viridis_c(option = \"C\", end = 0.75) +    labs(title    = \"Posterior Probability Distribution\",         subtitle = \"View on Correlation\",         x        = NULL,         y        = NULL) cov2cor(ffp_moments(x, p = ep)$sigma) #>            DAX       SMI       CAC      FTSE #> DAX  1.0000000 0.6932767 0.7317714 0.8346939 #> SMI  0.6932767 1.0000000 0.6260098 0.6113109 #> CAC  0.7317714 0.6260098 1.0000000 0.6535585 #> FTSE 0.8346939 0.6113109 0.6535585 1.0000000"},{"path":"/articles/views.html","id":"views-on-relative-performance","dir":"Articles","previous_headings":"","what":"Views on Relative Performance","title":"Views","text":"Assume investor believes DAX index outperform SMI amount, doesn’t know much. investor mild view performance assets, may want minimize following expression: \\[ \\sum_{j=1}^J x_j(ln(x_j) - ln(p_j)) \\] Subject constraint: \\[ \\sum_{j=1}^{J} x_j (V_{j, k} - V_{j, l}) \\ge 0 \\] , \\(x_j\\) yet determined probability vector; \\(V_{j, k}\\) \\(1859 \\times 1\\) column vector DAX returns \\(V_{j, l}\\) \\(1859 \\times 1\\) column vector SMI returns. case, \\(k\\) \\(l\\) subscripts refers column positions DAX SMI object x, respectively. Views relative performance can imposed view_on_rank: Assets expected outperform enter rank argument column positions right: assets left underperform assets right outperform. investor believes DAX \\(\\geq\\) SMI (asset first column outperform asset second column), fill rank = c(2, 1)5. optimization , , guided entropy_pooling function: Two important observations: Inequalities constraint handled nlminb solver. Use nloptr solnl, instead; Inequalities constraint require arguments b fulfilled rather Aeq beq. posterior probabilities presented bellow:  fact-check ongoing view, compare conditional vs. unconditional returns: Indeed, returns DAX adjusted upwards \\(17\\%\\), returns SMI revised downwards \\(6.5\\%\\). Notice returns CAC FTSE also affected. behavior tamed combining ranking condition views expected returns. See function bind_views() example.","code":"views <- view_on_rank(x = x, rank = c(2, 1)) views #> # ffp view #> Type:  View On Rank #> A :  Dim 1 x 1859  #> b :  Dim 1 x 1 ep <- entropy_pooling(   p      = p_j,    A      = views$A,    b      = views$b,    solver = \"nloptr\" ) ep #> <ffp[1859]> #> 0.0005145646 0.0005403155 0.0005470049 0.0005330238 0.0005446858 ... 0.0005469164 autoplot(ep) +    scale_color_viridis_c(option = \"C\", end = 0.75) +    labs(title    = \"Posterior Probability Distribution\",         subtitle = \"View on Ranking/Momentum\",         x        = NULL,         y        = NULL) conditional   <- ffp_moments(x, ep)$mu   unconditional <- colMeans(x)  conditional / unconditional - 1 #>         DAX         SMI         CAC        FTSE  #>  0.17274271 -0.06507206  0.13576460  0.06261161"},{"path":"/articles/views.html","id":"views-on-marginal-distribution","dir":"Articles","previous_headings":"","what":"Views on Marginal Distribution","title":"Views","text":"Assume investor view entire marginal distribution. One way add views marginal distributions matching first moments exactly, given order. Mathematically, investor minimizes relative entropy: \\[ \\sum_{j=1}^J x_j(ln(x_j) - ln(p_j)) \\] , say, two equality constraints (one \\(\\mu\\) one \\(\\sigma^2\\)): \\[ \\sum_{j=1}^J x_j V_{j,k}  =  \\sum_{j=z}^Z p_z \\hat{V}_{z,k} \\] \\[ \\sum_{j=1}^J x_j (V_{j,k})^2  =  \\sum_{z=1}^Z p_z (\\hat{V}_{z,k})^2 \\] \\(x_j\\) yet defined probability vector; \\(V_{j,k}\\) matrix empirical marginal distributions; \\(p_z\\) vector prior probabilities; \\(\\hat{V}_{z,k}\\) exogenous panel simulations consistent investor’s views. \\(j = z\\), panels \\(V_{j,k}\\) \\(\\hat{V}_{z,k}\\) number rows dimensions sides restrictions match. However, ’s possible set \\(z \\ge j\\) simulate larger panel \\(\\hat{V}_{z, k}\\). Keep mind though , \\(z \\ne j\\), two prior probabilities specified: one \\(p_j\\) (objective function) one \\(p_z\\) (views). Continuing example, consider margins x can approximated symmetric multivariate t-distribution. case, estimation can conducted amazing ghyp package, covers entire family generalized hyperbolic distributions: investor , can construct large panel statistical properties similar margins envisions: \\(100.000 \\times 4\\) matrix used match views view_on_marginal_distribution: objects simul p_z corresponds terms \\(\\hat{V}_{z,k}\\) transposed \\(p_z\\), respectively. Note \\(8\\) restrictions created, four moment marginal distribution (four assets “market”). prior views hand, optimization can quickly implemented: visual inspection vector ep:  ’s easy extend current example. instance, investor “tweak” fitted parameters stress-testing (.e. change degrees freedom, increase/decrease expected returns, etc) verify immediate impact P&L (VaR, CVaR, etc). Acknowledge restrictions harsh, scenarios heavily distorted satisfy views. case, one may need compute effective number scenarios (ENS). easy ens(): Rest investor calibrate statistic order get desired confidence level6.","code":"library(ghyp)  # multivariate t distribution dist_fit <- fit.tmv(data = x, symmetric = TRUE, silent = TRUE) dist_fit #> Symmetric Student-t Distribution: #>  #> Parameters: #>       nu  #> 6.151241  #>  #> mu: #> [1] 0.0007899665 0.0009594760 0.0004790250 0.0003811669 #>  #> sigma: #>               DAX          SMI          CAC         FTSE #> DAX  1.000013e-04 6.046969e-05 7.933384e-05 5.072439e-05 #> SMI  6.046969e-05 8.062728e-05 5.869208e-05 4.119624e-05 #> CAC  7.933384e-05 5.869208e-05 1.216927e-04 5.715865e-05 #> FTSE 5.072439e-05 4.119624e-05 5.715865e-05 6.398099e-05 #>  #> gamma: #> [1] 0 0 0 0 #>  #> log-likelihood: #> 26370.73 #>  #>  #> Call: #> fit.tmv(data = x, symmetric = TRUE, silent = TRUE) set.seed(123) # random numbers from `dist_fit` simul  <- rghyp(n = 100000, object = dist_fit) p_z <- rep(1 / 100000, 100000) views <- view_on_marginal_distribution(   x     = x,    simul = simul,    p     = p_z ) views #> # ffp view #> Type:  View On Marginal Distribution #> Aeq :  Dim 8 x 1859  #> beq :  Dim 8 x 1 ep <- entropy_pooling(   p      = p_j,    Aeq    = views$Aeq,    beq    = views$beq,    solver = \"nloptr\" ) ep #> <ffp[1859]> #> 0.000528748 0.0005678894 0.000536657 0.0005231905 0.0005349765 ... 0.0005324979 autoplot(ep) +    scale_color_viridis_c(option = \"C\", end = 0.75) +    labs(title    = \"Posterior Probability Distribution\",         subtitle = \"View on Marginal Distribution\",         x        = NULL,         y        = NULL) ens(ep) #> [1] 1857.356"},{"path":"/articles/views.html","id":"views-on-copulas","dir":"Articles","previous_headings":"","what":"Views on Copulas","title":"Views","text":"Assume investor like simulate different dependence structure market. Views change interdependence assets can implemented minimizing relative entropy: \\[ \\sum_{j=1}^J x_j(ln(x_j) - ln(p_j)) \\] Subject following restrictions: \\[ \\sum_{j=1}^J x_i U_{j,k} = 0.5\\]  \\[ \\sum_{j=1}^J x_j U_{j,k}U_{j,l}  =  \\sum_{z=1}^Z p_z \\hat{U}_{z,k}\\hat{U}_{z,l} \\] \\[ \\sum_{j=1}^J x_j U_{j,k}U_{j,l}U_{j,}  =  \\sum_{j=1}^J p_j \\hat{U}_{j,k}\\hat{U}_{j,l}\\hat{U}_{j,} \\] , first restriction matches first moment uniform distribution; second third restrictions pair cross-moments empirical copula, \\(U\\), simulated copula, \\(\\hat{U}\\); \\(x_j\\) yet discovered posterior distribution; \\(p_z\\) prior probability; \\(j = z\\), dimensions \\(p_j\\) \\(p_z\\) match. Among many available copulas, say investor wants model dependence market clayton copula ensure lower tail dependency go unnoticed. estimation simple implement package copula: First, copulas computed component-wise applying marginal empirical distribution every \\(k\\) column dataset. Second, pseudo-observations used fit Clayton copula Maximum-Likelihood (ML) method. Finally, large panel dimension \\(100.000 \\times 4\\) constructed match Clayton copula \\(\\hat \\alpha = 1.06\\), object cop. views market constructed view_on_copula: , solution minimum relative entropy can found one line code: autoplot method available objects ffp class:  stretch current example, assume investor stresses parameter \\(\\hat \\alpha = 1.06\\)7. Higher \\(\\alpha\\) values linked extreme occurrences left tails distribution. Whence, consider case \\(\\hat \\alpha = 5\\): Rerun previous steps (simulation, views optimization): find new posterior probability vector satisfy stress-test condition:","code":"library(copula)  # copula (pseudo-observation) u <- pobs(x)  # copula estimation cop <- fitCopula(   copula = claytonCopula(dim = ncol(x)),    data   = u,    method = \"ml\" )  # simulation r_cop <- rCopula(   n      = 100000,    copula = claytonCopula(param = cop@estimate, dim = 4) ) views <- view_on_copula(x = u, simul = r_cop, p = p_z) views #> # ffp view #> Type:  View On Copula #> Aeq :  Dim 34 x 1859  #> beq :  Dim 34 x 1 ep <- entropy_pooling(   p      = p_j,    Aeq    = views$Aeq,    beq    = views$beq,    solver = \"nloptr\" ) ep #> <ffp[1859]> #> 0.0001990935 0.0004161479 0.0008166059 0.0006512624 0.0003776943 ... 0.0003269579 autoplot(ep) +    scale_color_viridis_c(option = \"C\", end = 0.75) +    labs(title    = \"Posterior Probability Distribution\",         subtitle = \"View on Copulas\",         x        = NULL,         y        = NULL) cop@estimate <- 5 # simulation r_cop <- rCopula(   n      = 100000,    copula = claytonCopula(param = cop@estimate, dim = 4) )  # #views views <- view_on_copula(x = u, simul = r_cop, p = p_z)  # relative entropy ep <- entropy_pooling(   p      = p_j,    Aeq    = views$Aeq,    beq    = views$beq,    solver = \"nloptr\" ) autoplot(ep) +    scale_color_viridis_c(option = \"C\", end = 0.75) +    labs(title    = \"Posterior Probability Distribution\",         subtitle = \"View on Copulas\",         x        = NULL,         y        = NULL)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Bernardo Reckziegel. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reckziegel B (2022). ffp: Fully Flexible Probabilities Stress Testing Portfolio Construction. R package version 0.2.1.9000, https://github.com/Reckziegel/FFP.","code":"@Manual{,   title = {ffp: Fully Flexible Probabilities for Stress Testing and Portfolio Construction},   author = {Bernardo Reckziegel},   year = {2022},   note = {R package version 0.2.1.9000},   url = {https://github.com/Reckziegel/FFP}, }"},{"path":"/index.html","id":"fully-flexible-probabilities","dir":"","previous_headings":"","what":"Fully Flexible Probabilities for Stress Testing and Portfolio Construction","title":"Fully Flexible Probabilities for Stress Testing and Portfolio Construction","text":"Functions Scenario Analysis Risk Management Oftentimes, econometrician needs stress-test potential outcomes given set risk-drivers. process can computationally costly entire set scenarios needs repriced. overcome difficulty, Fully Flexible Probabilities (FFP) approach offers inexpensive way scenario generation: reprices probabilities associated scenario, instead scenarios . new probabilities defined, computations can performed quickly burden scenario generation left aside.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Fully Flexible Probabilities for Stress Testing and Portfolio Construction","text":"Install official version CRAN : Install development version github :","code":"install.packages(\"ffp\") # install.packages(\"devtools\") devtools::install_github(\"Reckziegel/ffp\")"},{"path":"/index.html","id":"probability-estimation","dir":"","previous_headings":"","what":"Probability Estimation","title":"Fully Flexible Probabilities for Stress Testing and Portfolio Construction","text":"package ffp comes five functions extract probabilities historical scenarios: exp_decay(): accounts time-changing nature volatility giving weight recent observations; crisp(): selects scenarios logical statement satisfied; kernel_normal(): generalizes crisp condition wrapping scenarios normal kernel; kernel_entropy(): uses entropy-polling satisfy conditioning statement; double_decay(): uses entropy-polling double-decay factor constrain first two moments distribution.","code":""},{"path":"/index.html","id":"stress-testing-and-portfolio-construction","dir":"","previous_headings":"","what":"Stress-Testing and Portfolio Construction","title":"Fully Flexible Probabilities for Stress Testing and Portfolio Construction","text":"package also offers eight different constructors make easier input views market portfolio optimization (mean-variance, risk-parity, etc.): view_on_mean() view_on_covariance() view_on_correlation() view_on_volatility() view_on_rank() view_on_copula() view_on_marginal_distribution() view_on_joint_distribution() output list entropy_pooling() can handle easily. combine multiple views single object use bind_views().","code":""},{"path":"/index.html","id":"scenario-analysis","dir":"","previous_headings":"","what":"Scenario Analysis","title":"Fully Flexible Probabilities for Stress Testing and Portfolio Construction","text":"new probabilities estimated, bootstrap_scenarios() can used sample data, keeping structure empirical copulas intact. main statistics arbitrary scenarios can computed empirical_stats().","code":""},{"path":"/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Fully Flexible Probabilities for Stress Testing and Portfolio Construction","text":"Attilio Meucci (2021). Historical Scenarios Fully Flexible Probabilities (https://www.mathworks.com/matlabcentral/fileexchange/31360-historical-scenarios--fully-flexible-probabilities), MATLAB Central File Exchange. Retrieved June 11, 2021. De Santis, G., R. Litterman, . Vesval, K. Winkelmann, 2003, Covariance matrix estimation, Modern investment management: equilibrium approach, Wiley. Meucci, Attilio, Fully Flexible Views: Theory Practice (August 8, 2008). Fully Flexible Views: Theory Practice, Risk, Vol. 21, . 10, pp. 97-102, October 2008, Available SSRN: https://www.ssrn.com/abstract=1213325 Meucci, Attilio, Historical Scenarios Fully Flexible Probabilities (October 23, 2010). GARP Risk Professional, pp. 47-51, December 2010, Available SSRN: https://www.ssrn.com/abstract=1696802 http://dx.doi.org/10.2139/ssrn.1696802","code":""},{"path":"/reference/DoubleDecay.html","id":null,"dir":"Reference","previous_headings":"","what":"Double-Decay Covariance Matrix — DoubleDecay","title":"Double-Decay Covariance Matrix — DoubleDecay","text":"function computes covariance matrix using two different decay factors.","code":""},{"path":"/reference/DoubleDecay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Double-Decay Covariance Matrix — DoubleDecay","text":"","code":"DoubleDecay(x, decay_low, decay_high)"},{"path":"/reference/DoubleDecay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Double-Decay Covariance Matrix — DoubleDecay","text":"x set relevant risk drivers. decay_low numeric value low decay (long half-life). decay_high numeric value high decay (short half-life).","code":""},{"path":"/reference/DoubleDecay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Double-Decay Covariance Matrix — DoubleDecay","text":"list posterior mean ans sigma.","code":""},{"path":"/reference/DoubleDecay.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Double-Decay Covariance Matrix — DoubleDecay","text":"common practice estimate covariance risk drivers using high decay (short half-life) volatilities low decay (long half-life) correlations.","code":""},{"path":"/reference/autoplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Inspection of a ffp object with ggplot2 — autoplot.ffp","title":"Inspection of a ffp object with ggplot2 — autoplot.ffp","text":"Extends autoplot method ffp class.","code":""},{"path":"/reference/autoplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inspection of a ffp object with ggplot2 — autoplot.ffp","text":"","code":"# S3 method for ffp autoplot(object, color = TRUE, ...)  # S3 method for ffp plot(object, ...)"},{"path":"/reference/autoplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inspection of a ffp object with ggplot2 — autoplot.ffp","text":"object objected ffp class. color logical flag indicating whether () color argument added ggplot2 aesthetics. ... Additional arguments passed autoplot.","code":""},{"path":"/reference/autoplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inspection of a ffp object with ggplot2 — autoplot.ffp","text":"ggplot2 object.","code":""},{"path":"/reference/autoplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inspection of a ffp object with ggplot2 — autoplot.ffp","text":"","code":"library(ggplot2)  x <- exp_decay(EuStockMarkets, 0.001) y <- exp_decay(EuStockMarkets, 0.01)  autoplot(x) +   scale_color_viridis_c()  autoplot(y) +   scale_color_viridis_c()"},{"path":"/reference/bind_probs.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack Flexible Probabilities — bind_probs","title":"Stack Flexible Probabilities — bind_probs","text":"function mimics dplyr bind. useful different ffp objects want stack tidy (long) format.","code":""},{"path":"/reference/bind_probs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack Flexible Probabilities — bind_probs","text":"","code":"bind_probs(...)"},{"path":"/reference/bind_probs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack Flexible Probabilities — bind_probs","text":"... ffp objects combine.","code":""},{"path":"/reference/bind_probs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack Flexible Probabilities — bind_probs","text":"tidy tibble. output adds two new columns: rowid (integer) row number realization; key (factor) keeps track ffp inputs separated objects.","code":""},{"path":[]},{"path":"/reference/bind_probs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stack Flexible Probabilities — bind_probs","text":"","code":"library(ggplot2) library(dplyr, warn.conflicts = FALSE)  x <- exp_decay(EuStockMarkets, lambda = 0.001) y <- exp_decay(EuStockMarkets, lambda = 0.002)  bind_probs(x, y) #> # A tibble: 3,720 × 3 #>    rowid        probs fn                                            #>    <int>        <ffp> <fct>                                         #>  1     1 0.0001844669 exp_decay(x = EuStockMarkets, lambda = 0.001) #>  2     2 0.0001846515 exp_decay(x = EuStockMarkets, lambda = 0.001) #>  3     3 0.0001848363 exp_decay(x = EuStockMarkets, lambda = 0.001) #>  4     4 0.0001850212 exp_decay(x = EuStockMarkets, lambda = 0.001) #>  5     5 0.0001852063 exp_decay(x = EuStockMarkets, lambda = 0.001) #>  6     6 0.0001853916 exp_decay(x = EuStockMarkets, lambda = 0.001) #>  7     7 0.0001855771 exp_decay(x = EuStockMarkets, lambda = 0.001) #>  8     8 0.0001857627 exp_decay(x = EuStockMarkets, lambda = 0.001) #>  9     9 0.0001859486 exp_decay(x = EuStockMarkets, lambda = 0.001) #> 10    10 0.0001861346 exp_decay(x = EuStockMarkets, lambda = 0.001) #> # … with 3,710 more rows  bind_probs(x, y) %>%   ggplot(aes(x = rowid, y = probs, color = fn)) +   geom_line() +   scale_color_viridis_d() +   theme(legend.position=\"bottom\") #> Don't know how to automatically pick scale for object of type ffp/vctrs_vctr. Defaulting to continuous."},{"path":"/reference/bind_views.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack Different Views — bind_views","title":"Stack Different Views — bind_views","text":"Bind views entropy programming.","code":""},{"path":"/reference/bind_views.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack Different Views — bind_views","text":"","code":"bind_views(...)"},{"path":"/reference/bind_views.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack Different Views — bind_views","text":"... Objects class ffp_views combine.","code":""},{"path":"/reference/bind_views.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack Different Views — bind_views","text":"list view class.","code":""},{"path":"/reference/bind_views.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stack Different Views — bind_views","text":"","code":"library(ggplot2)  # Invariant ret <- diff(log(EuStockMarkets)) n   <- nrow(ret)  # Prior probabilities (usually equal weight scheme) prior <- rep(1 / n, n)  # Prior belief for expected returns (here is 0% for each asset) view_mean <- view_on_mean(x = ret, mean = rep(0, 4))  #' view on volatility vol <- apply(ret, 2, stats::sd) * 1.1 # volatility 10% higher than average view_volatility <- view_on_volatility(x = ret, vol = vol)  views_comb <- bind_views(view_mean, view_volatility) views_comb #> # ffp view #> Type:  Multiple Views #> Aeq :  Dim 8 x 1859  #> beq :  Dim 8 x 1  #> A :  Dim 0 x 1  #> b :  Dim 0 x 1   ep <- entropy_pooling(p      = prior,                       Aeq    = views_comb$Aeq,                       beq    = views_comb$beq,                       A      = views_comb$A,                       b      = views_comb$b,                       solver = \"nlminb\") autoplot(ep)"},{"path":"/reference/bootstrap_scenarios.html","id":null,"dir":"Reference","previous_headings":"","what":"Flexible Probabilities Driven Bootstrap — bootstrap_scenarios","title":"Flexible Probabilities Driven Bootstrap — bootstrap_scenarios","text":"Resamples historical scenarios flexible probabilities.","code":""},{"path":"/reference/bootstrap_scenarios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flexible Probabilities Driven Bootstrap — bootstrap_scenarios","text":"","code":"bootstrap_scenarios(x, p, n)  # S3 method for numeric bootstrap_scenarios(x, p, n)  # S3 method for matrix bootstrap_scenarios(x, p, n)  # S3 method for ts bootstrap_scenarios(x, p, n)  # S3 method for xts bootstrap_scenarios(x, p, n)  # S3 method for tbl bootstrap_scenarios(x, p, n)  # S3 method for data.frame bootstrap_scenarios(x, p, n)"},{"path":"/reference/bootstrap_scenarios.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flexible Probabilities Driven Bootstrap — bootstrap_scenarios","text":"x time series defining scenario-probability distribution. p object ffp class. n integer scalar number scenarios generated.","code":""},{"path":"/reference/bootstrap_scenarios.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flexible Probabilities Driven Bootstrap — bootstrap_scenarios","text":"tibble number rows equal n.","code":""},{"path":"/reference/bootstrap_scenarios.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Flexible Probabilities Driven Bootstrap — bootstrap_scenarios","text":"argument x supposed size p.","code":""},{"path":"/reference/bootstrap_scenarios.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flexible Probabilities Driven Bootstrap — bootstrap_scenarios","text":"","code":"set.seed(123) ret <- diff(log(EuStockMarkets)) ew  <- rep(1 / nrow(ret), nrow(ret))  bootstrap_scenarios(x = ret, p = as_ffp(ew), n = 10) #> # A tibble: 10 × 4 #>         DAX        SMI      CAC      FTSE #>       <dbl>      <dbl>    <dbl>     <dbl> #>  1  0.00313 -0.00611    0.00344  0.00349  #>  2  0.00180  0.00548   -0.00514 -0.000790 #>  3  0.00355 -0.00732   -0.0111   0.00138  #>  4 -0.0111  -0.00350   -0.00344 -0.00667  #>  5  0.00691  0.00824    0.00385 -0.00216  #>  6  0.00452  0.00608    0.00938  0.0173   #>  7  0.00351  0.0000394 -0.00527  0.000658 #>  8  0.00349  0.00387    0        0.00888  #>  9  0.0100   0.00157   -0.00274  0.00101  #> 10 -0.00686 -0.00927    0.00165  0.0112"},{"path":"/reference/check_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function used to check the validity of inputs. — check_input","title":"Internal function used to check the validity of inputs. — check_input","text":"Internal function used check validity inputs.","code":""},{"path":"/reference/check_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function used to check the validity of inputs. — check_input","text":"","code":"check_input(x)  # S3 method for default check_input(x)  # S3 method for numeric check_input(x)  # S3 method for double check_input(x)  # S3 method for matrix check_input(x)  # S3 method for xts check_input(x)  # S3 method for tbl_df check_input(x)"},{"path":"/reference/check_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function used to check the validity of inputs. — check_input","text":"x object passed functions package.","code":""},{"path":"/reference/check_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function used to check the validity of inputs. — check_input","text":"matrix","code":""},{"path":"/reference/crisp.html","id":null,"dir":"Reference","previous_headings":"","what":"Full Information by Market Conditioning — crisp","title":"Full Information by Market Conditioning — crisp","text":"Give full weight occurrences satisfies logical condition.","code":""},{"path":"/reference/crisp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full Information by Market Conditioning — crisp","text":"","code":"crisp(x, lgl)  # S3 method for default crisp(x, lgl)  # S3 method for numeric crisp(x, lgl)  # S3 method for matrix crisp(x, lgl)  # S3 method for ts crisp(x, lgl)  # S3 method for xts crisp(x, lgl)  # S3 method for data.frame crisp(x, lgl)  # S3 method for tbl_df crisp(x, lgl)"},{"path":"/reference/crisp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full Information by Market Conditioning — crisp","text":"x univariate multivariate distribution. lgl logical vector TRUE's FALSE's indicating scenarios considered.","code":""},{"path":"/reference/crisp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full Information by Market Conditioning — crisp","text":"numerical vector class ffp new probabilities distribution.","code":""},{"path":[]},{"path":"/reference/crisp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full Information by Market Conditioning — crisp","text":"","code":"library(ggplot2) # invariance (stationarity) ret <- diff(log(EuStockMarkets))  # full weight on scenarios where CAC returns were above 2% market_condition <- crisp(x = ret, ret[ , 3] > 0.02) market_condition #> <ffp[1859]> #> 1.470588e-32 1.470588e-32 1.470588e-32 1.470588e-32 1.470588e-32 ... 1.470588e-32  autoplot(market_condition) +   scale_color_viridis_c()"},{"path":"/reference/db.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset used in Historical Scenarios with Fully Flexible Probabilities\n(matrix format). — db","title":"Dataset used in Historical Scenarios with Fully Flexible Probabilities\n(matrix format). — db","text":"Dataset used Historical Scenarios Fully Flexible Probabilities (matrix format).","code":""},{"path":"/reference/db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset used in Historical Scenarios with Fully Flexible Probabilities\n(matrix format). — db","text":"","code":"db"},{"path":"/reference/db.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset used in Historical Scenarios with Fully Flexible Probabilities\n(matrix format). — db","text":"object class matrix (inherits array) 1083 rows 9 columns.","code":""},{"path":[]},{"path":"/reference/db_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset used in Historical Scenarios with Fully Flexible Probabilities\n(tibble format). — db_tbl","title":"Dataset used in Historical Scenarios with Fully Flexible Probabilities\n(tibble format). — db_tbl","text":"Dataset used Historical Scenarios Fully Flexible Probabilities (tibble format).","code":""},{"path":"/reference/db_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset used in Historical Scenarios with Fully Flexible Probabilities\n(tibble format). — db_tbl","text":"","code":"db_tbl"},{"path":"/reference/db_tbl.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset used in Historical Scenarios with Fully Flexible Probabilities\n(tibble format). — db_tbl","text":"object class tbl_df (inherits tbl, data.frame) 1083 rows 9 columns.","code":""},{"path":[]},{"path":"/reference/double_decay.html","id":null,"dir":"Reference","previous_headings":"","what":"Flexible Probabilities using Partial Information — double_decay","title":"Flexible Probabilities using Partial Information — double_decay","text":"Match different decay-factors covariance matrix.","code":""},{"path":"/reference/double_decay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flexible Probabilities using Partial Information — double_decay","text":"","code":"double_decay(x, slow, fast)  # S3 method for default double_decay(x, slow, fast)  # S3 method for numeric double_decay(x, slow, fast)  # S3 method for matrix double_decay(x, slow, fast)  # S3 method for ts double_decay(x, slow, fast)  # S3 method for xts double_decay(x, slow, fast)  # S3 method for tbl double_decay(x, slow, fast)  # S3 method for data.frame double_decay(x, slow, fast)"},{"path":"/reference/double_decay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flexible Probabilities using Partial Information — double_decay","text":"x univariate multivariate distribution. slow double long half-life (slow decay) correlation matrix. fast double short-life (high decay) volatility.","code":""},{"path":"/reference/double_decay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flexible Probabilities using Partial Information — double_decay","text":"numerical vector class ffp new probabilities distribution.","code":""},{"path":"/reference/double_decay.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Flexible Probabilities using Partial Information — double_decay","text":"De Santis, G., R. Litterman, . Vesval, K. Winkelmann, 2003, Covariance matrix estimation, Modern investment management: equilibrium approach, Wiley.","code":""},{"path":[]},{"path":"/reference/double_decay.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flexible Probabilities using Partial Information — double_decay","text":"","code":"# \\donttest{   library(ggplot2)    slow <- 0.0055   fast <- 0.0166   ret <- diff(log(EuStockMarkets))    dd <- double_decay(ret, slow, fast)   dd #> <ffp[1859]> #> 0.000372852 0.000398851 0.0005750612 0.0004815779 0.000553617 ... 0.0007460361    autoplot(dd) +     scale_color_viridis_c()  # }"},{"path":"/reference/empirical_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Statistics for Empirical Distributions — empirical_stats","title":"Summary Statistics for Empirical Distributions — empirical_stats","text":"Computes mean, standard deviation, skewness, kurtosis, Value--Risk (VaR) Conditional Value--Risk CVaR) flexible probabilities.","code":""},{"path":"/reference/empirical_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Statistics for Empirical Distributions — empirical_stats","text":"","code":"empirical_stats(x, p, level = 0.01)  # S3 method for default empirical_stats(x, p, level = 0.01)  # S3 method for numeric empirical_stats(x, p, level = 0.01)  # S3 method for matrix empirical_stats(x, p, level = 0.01)  # S3 method for xts empirical_stats(x, p, level = 0.01)  # S3 method for ts empirical_stats(x, p, level = 0.01)  # S3 method for data.frame empirical_stats(x, p, level = 0.01)  # S3 method for tbl_df empirical_stats(x, p, level = 0.01)"},{"path":"/reference/empirical_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Statistics for Empirical Distributions — empirical_stats","text":"x time series defining scenario-probability distribution. p object ffp class. level number desired probability level. default level = 0.01.","code":""},{"path":"/reference/empirical_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Statistics for Empirical Distributions — empirical_stats","text":"tidy tibble 3 columns: stat: column Mu, Std, Skew, Kurt, VaR CVaR. name: asset names. value: computed value statistic.","code":""},{"path":"/reference/empirical_stats.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Statistics for Empirical Distributions — empirical_stats","text":"data x p expected number rows (size).","code":""},{"path":"/reference/empirical_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Statistics for Empirical Distributions — empirical_stats","text":"","code":"library(dplyr, warn.conflicts = FALSE) library(ggplot2)  ret <- diff(log(EuStockMarkets))  # with equal weights (standard scenario) ew  <- rep(1 / nrow(ret), nrow(ret)) empirical_stats(x = ret, p = as_ffp(ew)) %>%   ggplot(aes(x = name, y = value)) +   geom_col() +   facet_wrap(~stat, scales = \"free\") +   labs(x = NULL, y = NULL)   # with ffp exp_smooth <- exp_decay(ret, 0.015) empirical_stats(ret, exp_smooth) %>%   ggplot(aes(x = name, y = value)) +   geom_col() +   facet_wrap(~stat, scales = \"free\") +   labs(x = NULL, y = NULL)"},{"path":"/reference/ens.html","id":null,"dir":"Reference","previous_headings":"","what":"Effective Number of Scenarios — ens","title":"Effective Number of Scenarios — ens","text":"Shows many scenarios effectively considered using flexible probabilities.","code":""},{"path":"/reference/ens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Effective Number of Scenarios — ens","text":"","code":"ens(p)"},{"path":"/reference/ens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Effective Number of Scenarios — ens","text":"p object ffp class.","code":""},{"path":"/reference/ens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Effective Number of Scenarios — ens","text":"single double.","code":""},{"path":"/reference/ens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Effective Number of Scenarios — ens","text":"","code":"set.seed(123) p <- exp_decay(stats::rnorm(100), 0.01)  # ens is smaller than 100 ens(p) #> [1] 96.01674"},{"path":"/reference/entropy_pooling.html","id":null,"dir":"Reference","previous_headings":"","what":"Numerical Entropy Minimization — entropy_pooling","title":"Numerical Entropy Minimization — entropy_pooling","text":"function solves entropy minimization problem equality inequality constraints. solution vector posterior probabilities distorts least prior (equal-weights probabilities) given constraints (views market).","code":""},{"path":"/reference/entropy_pooling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numerical Entropy Minimization — entropy_pooling","text":"","code":"entropy_pooling(   p,   A = NULL,   b = NULL,   Aeq = NULL,   beq = NULL,   solver = c(\"nlminb\", \"solnl\", \"nloptr\"),   ... )"},{"path":"/reference/entropy_pooling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numerical Entropy Minimization — entropy_pooling","text":"p vector prior probabilities. linear inequality constraint (left-hand side). b linear inequality constraint (right-hand side). Aeq linear equality constraint (left-hand side). beq linear equality constraint (right-hand side). solver character. One : \"nlminb\", \"solnl\" \"nloptr\". ... arguments passed one solvers.","code":""},{"path":"/reference/entropy_pooling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Numerical Entropy Minimization — entropy_pooling","text":"vector posterior probabilities.","code":""},{"path":"/reference/entropy_pooling.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Numerical Entropy Minimization — entropy_pooling","text":"imposing views constraints need specify non-negativity constraint probabilities, done automatically entropy_pooling. arguments accepted ..., please see documentation nlminb, solnl, nloptr examples bellow.","code":""},{"path":"/reference/entropy_pooling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Numerical Entropy Minimization — entropy_pooling","text":"","code":"# setup ret <- diff(log(EuStockMarkets)) n   <- nrow(ret)  # View on expected returns (here is 2% for each asset) mean <- rep(0.02, 4)  # Prior probabilities (usually equal weight scheme) prior <- rep(1 / n, n)  # View views <- view_on_mean(x = ret, mean = mean)  # Optimization ep <- entropy_pooling(  p      = prior,  Aeq    = views$Aeq,  beq    = views$beq,  solver = \"nlminb\" ) ep #> <ffp[1859]> #> 0.0002626139 1.758547e-05 0.0003425248 8.978951e-05 6.135271e-06 ... 0.002028742  ### Using the ... argument to control the optimization parameters  # nlminb ep <- entropy_pooling(  p      = prior,  Aeq    = views$Aeq,  beq    = views$beq,  solver = \"nlminb\",  control = list(      eval.max = 1000,      iter.max = 1000,      trace    = TRUE    ) ) #>   0:    0.36787944:  0.00000  0.00000  0.00000  0.00000  0.00000 #>   1:   0.058529435: -0.0197601 -0.0196991 -0.0198392 -0.0198411 -0.632121 #>   2:   0.025855388: -0.0580704 -0.0577859 -0.0584405 -0.0584522 -1.23661 #>   3: -0.0039314351: -0.0601613 -0.0598133 -0.0606155 -0.0606329 -0.960871 #>   4: -0.0062039413: -0.0798744 -0.0793660 -0.0805394 -0.0805680 -0.994812 #>   5:  -0.010307925: -0.141800 -0.140779 -0.143140 -0.143210 -1.03756 #>   6:  -0.019570052: -0.316315 -0.313846 -0.319572 -0.319772 -1.09779 #>   7:  -0.043181545: -0.819004 -0.812370 -0.827790 -0.828413 -1.19256 #>   8:   -0.10177381: -2.16618 -2.14843 -2.18979 -2.19169 -1.33121 #>   9:   -0.24450670: -5.57753 -5.53182 -5.63866 -5.64428 -1.50627 #>  10:   -0.56153114: -13.4230 -13.3136 -13.5703 -13.5859 -1.63871 #>  11:   -0.94888011: -21.2678 -21.0960 -21.5008 -21.5292 -1.52434 #>  12:    -1.6484869: -36.0658 -35.7809 -36.4590 -36.5217 -0.820266 #>  13:    -1.9955215: -36.7399 -36.4578 -37.1372 -37.2208 -0.187631 #>  14:    -2.0494729: -39.7300 -39.4294 -40.1580 -40.2589 0.0440528 #>  15:    -2.0751860: -43.2371 -42.9197 -43.6984 -43.8330 0.347319 #>  16:    -2.0765785: -43.3910 -43.0785 -43.8509 -44.0018 0.399315 #>  17:    -2.0767596: -43.4590 -43.1528 -43.9161 -44.0850 0.417657 #>  18:    -2.0769135: -43.4939 -43.1979 -43.9459 -44.1427 0.427405 #>  19:    -2.0775638: -43.5805 -43.3378 -44.0053 -44.3450 0.453965 #>  20:    -2.0790107: -43.6821 -43.5731 -44.0377 -44.7336 0.491159 #>  21:    -2.0829909: -43.8109 -44.0959 -43.9615 -45.7033 0.557356 #>  22:    -2.0929607: -43.8973 -45.2158 -43.5082 -47.9880 0.666737 #>  23:    -2.1182943: -43.7455 -47.7872 -41.9313 -53.6180 0.856961 #>  24:    -2.1798935: -42.8042 -53.7356 -37.3807 -67.2880  1.19084 #>  25:    -2.3151349: -39.7853 -67.2182 -25.7118 -99.2417  1.77838 #>  26:    -2.4186844: -33.9735 -87.9670 -5.96992 -149.692  2.46898 #>  27:    -2.4900606: -34.8994 -78.3218 -12.4289 -128.179  1.94373 #>  28:    -2.5775299: -32.6956 -71.8257 -12.4512 -116.778  1.27932 #>  29:    -2.6068010: -29.5070 -70.8620 -8.07330 -118.207 0.891005 #>  30:    -2.6099515: -29.4968 -73.2253 -6.82148 -123.235  1.04082 #>  31:    -2.6100208: -29.4780 -72.9504 -6.93546 -122.666  1.03080 #>  32:    -2.6100410: -29.4209 -72.8983 -6.87400 -122.608  1.02619 #>  33:    -2.6101039: -29.2902 -72.8182 -6.70931 -122.539  1.01806 #>  34:    -2.6102275: -29.1332 -72.7544 -6.48708 -122.475  1.00891 #>  35:    -2.6105851: -28.8556 -72.7115 -6.03600 -122.370 0.993029 #>  36:    -2.6114768: -28.4424 -72.8223 -5.21726 -122.217 0.969753 #>  37:    -2.6137938: -27.8170 -73.4617 -3.57894 -121.995 0.935343 #>  38:    -2.6195151: -26.9722 -75.6085 -0.279708 -121.712 0.891008 #>  39:    -2.6326800: -26.0838 -81.5175  6.28270 -121.447 0.850300 #>  40:    -2.6574796: -25.9140 -94.4837  17.5717 -121.450 0.861513 #>  41:    -2.6885771: -27.7660 -113.260  30.2660 -122.048 0.997768 #>  42:    -2.7143812: -31.4827 -126.678  35.1710 -123.157  1.23449 #>  43:    -2.7264724: -34.9709 -129.463  31.4215 -124.392  1.43257 #>  44:    -2.7267015: -35.0093 -128.332  30.3531 -124.673  1.42848 #>  45:    -2.7267088: -34.9401 -128.047  30.2254 -124.693  1.42253 #>  46:    -2.7267089: -34.9366 -128.034  30.2215 -124.681  1.42188 #>  47:    -2.7267092: -34.9311 -128.010  30.2108 -124.656  1.42080 #>  48:    -2.7267098: -34.9246 -127.984  30.1979 -124.626  1.41959 #>  49:    -2.7267116: -34.9094 -127.936  30.1711 -124.571  1.41737 #>  50:    -2.7267161: -34.8779 -127.867  30.1240 -124.484  1.41395 #>  51:    -2.7267279: -34.8046 -127.763  30.0309 -124.338  1.40837 #>  52:    -2.7267578: -34.6340 -127.626  29.8448 -124.104  1.39970 #>  53:    -2.7268314: -34.2361 -127.485  29.4630 -123.738  1.38694 #>  54:    -2.7269947: -33.3736 -127.469  28.7210 -123.237  1.37141 #>  55:    -2.7272818: -31.8438 -127.862  27.5310 -122.780  1.36158 #>  56:    -2.7275727: -30.3208 -128.700  26.4829 -122.800  1.37111 #>  57:    -2.7277430: -29.4401 -129.659  26.0224 -123.331  1.39753 #>  58:    -2.7277672: -29.5781 -129.917  26.2155 -123.680  1.41099 #>  59:    -2.7277689: -29.7310 -129.932  26.3474 -123.771  1.41396 #>  60:    -2.7277690: -29.7537 -129.923  26.3637 -123.774  1.41397 #>  61:    -2.7277690: -29.7549 -129.922  26.3644 -123.773  1.41395 ep #> <ffp[1859]> #> 0.0002626139 1.758547e-05 0.0003425248 8.978951e-05 6.135271e-06 ... 0.002028742  # nloptr ep <- entropy_pooling(  p      = prior,  Aeq    = views$Aeq,  beq    = views$beq,  solver = \"nloptr\",  control = list(      xtol_rel = 1e-10,      maxeval  = 1000,      check_derivatives = TRUE    ) ) #> Checking gradients of objective function. #> Derivative checker results: 0 error(s) detected. #>  #>   eval_grad_f[ 1, 1 ] = 1.976013e-02 ~ 1.975961e-02   [2.616200e-05] #>   eval_grad_f[ 2, 1 ] = 1.969911e-02 ~ 1.969862e-02   [2.477148e-05] #>   eval_grad_f[ 3, 1 ] = 1.983922e-02 ~ 1.983871e-02   [2.576603e-05] #>   eval_grad_f[ 4, 1 ] = 1.984108e-02 ~ 1.984060e-02   [2.417970e-05] #>   eval_grad_f[ 5, 1 ] = 6.321206e-01 ~ 6.321204e-01   [2.737810e-07] #>  ep #> <ffp[1859]> #> 0.0002626141 1.75855e-05 0.0003425251 8.978965e-05 6.135285e-06 ... 0.002028743"},{"path":"/reference/exp_decay.html","id":null,"dir":"Reference","previous_headings":"","what":"Full Information by Exponential Decay — exp_decay","title":"Full Information by Exponential Decay — exp_decay","text":"Exponential smoothing twists probabilities giving relatively weight recent observations exponential rate.","code":""},{"path":"/reference/exp_decay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full Information by Exponential Decay — exp_decay","text":"","code":"exp_decay(x, lambda)  # S3 method for default exp_decay(x, lambda)  # S3 method for numeric exp_decay(x, lambda)  # S3 method for matrix exp_decay(x, lambda)  # S3 method for ts exp_decay(x, lambda)  # S3 method for xts exp_decay(x, lambda)  # S3 method for data.frame exp_decay(x, lambda)  # S3 method for tbl exp_decay(x, lambda)"},{"path":"/reference/exp_decay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full Information by Exponential Decay — exp_decay","text":"x univariate multivariate distribution. lambda double decay parameter.","code":""},{"path":"/reference/exp_decay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full Information by Exponential Decay — exp_decay","text":"numerical vector class ffp new probabilities distribution.","code":""},{"path":"/reference/exp_decay.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Full Information by Exponential Decay — exp_decay","text":"half-life linked lambda parameter follows: HL = log(2) / lambda. example: log(2) / 0.0166 approximately 42. , parameter lambda 0.0166 can associated half-life two-months (21 * 2).","code":""},{"path":[]},{"path":"/reference/exp_decay.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full Information by Exponential Decay — exp_decay","text":"","code":"library(ggplot2)  # long half_life long_hl <- exp_decay(EuStockMarkets, 0.001) long_hl #> <ffp[1860]> #> 0.0001844669 0.0001846515 0.0001848363 0.0001850212 0.0001852063 ... 0.001183783 autoplot(long_hl) +   scale_color_viridis_c()   # short half_life short_hl <- exp_decay(EuStockMarkets, 0.015) short_hl #> <ffp[1860]> #> 1.154879e-14 1.172333e-14 1.19005e-14 1.208036e-14 1.226293e-14 ... 0.01488806 autoplot(short_hl) +   scale_color_viridis_c()"},{"path":"/reference/ffp-vctrs.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal vctrs methods — ffp-vctrs","title":"Internal vctrs methods — ffp-vctrs","text":"Internal vctrs methods","code":""},{"path":"/reference/ffp-vctrs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal vctrs methods — ffp-vctrs","text":"","code":"new_ffp(x = double(), ...)  # S3 method for ffp vec_ptype_abbr(x, ...)  # S3 method for ffp.ffp vec_ptype2(x, y, ...)  # S3 method for ffp.double vec_ptype2(x, y, ...)  # S3 method for double.ffp vec_ptype2(x, y, ...)  # S3 method for ffp.ffp vec_cast(x, to, ...)  # S3 method for ffp.double vec_cast(x, to, ...)  # S3 method for double.ffp vec_cast(x, to, ...)  # S3 method for ffp obj_print_data(x, ...)  # S3 method for ffp vec_math(.fn, .x, ...)  # S3 method for ffp vec_arith(op, x, y, ...)"},{"path":"/reference/ffp-vctrs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal vctrs methods — ffp-vctrs","text":"x numeric vector.","code":""},{"path":"/reference/ffp-vctrs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal vctrs methods — ffp-vctrs","text":"return value, called side effects.","code":""},{"path":"/reference/ffp.html","id":null,"dir":"Reference","previous_headings":"","what":"Manipulate the ffp Class — ffp","title":"Manipulate the ffp Class — ffp","text":"Helpers Constructors ffp.","code":""},{"path":"/reference/ffp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manipulate the ffp Class — ffp","text":"","code":"ffp(x = double(), ...)  is_ffp(x)  as_ffp(x)  # S3 method for default as_ffp(x)  # S3 method for integer as_ffp(x)"},{"path":"/reference/ffp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manipulate the ffp Class — ffp","text":"x ffp(): numeric vector. is_ffp(): object tested. as_ffp(): object convert ffp. ... Additional attributes passed ffp.","code":""},{"path":"/reference/ffp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manipulate the ffp Class — ffp","text":"ffp() as_ffp() return S3 vector class ffp (built upon double's); is_ffp() returns logical object.","code":""},{"path":"/reference/ffp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Manipulate the ffp Class — ffp","text":"ffp class designed interact doubles, output c(ffp, double) c(double, ffp) always return double (ffp object), since way guarantee interaction numeric vector probability also probability.","code":""},{"path":"/reference/ffp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manipulate the ffp Class — ffp","text":"","code":"set.seed(123) p <- runif(5) p <- p / sum(p)  is_ffp(p) #> [1] FALSE as_ffp(p) #> <ffp[5]> #> 0.08692491 0.2382778 0.1236198 0.2669061 0.2842713"},{"path":"/reference/ffp_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Moments with Flexible Probabilities — ffp_moments","title":"Moments with Flexible Probabilities — ffp_moments","text":"Computes location dispersion statistics flexible probabilities.","code":""},{"path":"/reference/ffp_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moments with Flexible Probabilities — ffp_moments","text":"","code":"ffp_moments(x, p = NULL)  # S3 method for default ffp_moments(x, p = NULL)  # S3 method for numeric ffp_moments(x, p = NULL)  # S3 method for matrix ffp_moments(x, p = NULL)  # S3 method for xts ffp_moments(x, p = NULL)  # S3 method for data.frame ffp_moments(x, p = NULL)  # S3 method for tbl_df ffp_moments(x, p = NULL)"},{"path":"/reference/ffp_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moments with Flexible Probabilities — ffp_moments","text":"x tabular (non-tidy) data structure. p object ffp class.","code":""},{"path":"/reference/ffp_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moments with Flexible Probabilities — ffp_moments","text":"list 2 elements: mu sigma.","code":""},{"path":"/reference/ffp_moments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Moments with Flexible Probabilities — ffp_moments","text":"","code":"x <- matrix(diff(log(EuStockMarkets)), ncol = 4) colnames(x) <- colnames(EuStockMarkets) p <- stats::runif(nrow(x)) p <- p / sum(p)  ffp_moments(x = x, p = p) #> $mu #>          DAX          SMI          CAC         FTSE  #> 0.0006590193 0.0006674141 0.0004552631 0.0004186991  #>  #> $sigma #>               DAX          SMI          CAC         FTSE #> DAX  1.058414e-04 6.665733e-05 8.131371e-05 5.274301e-05 #> SMI  6.665733e-05 8.566093e-05 6.239321e-05 4.306845e-05 #> CAC  8.131371e-05 6.239321e-05 1.199025e-04 5.703934e-05 #> FTSE 5.274301e-05 4.306845e-05 5.703934e-05 6.243929e-05 #>   # compare with the standard approach colMeans(x) #>          DAX          SMI          CAC         FTSE  #> 0.0006520417 0.0008178997 0.0004370540 0.0004319851  cov(x) #>               DAX          SMI          CAC         FTSE #> DAX  1.061072e-04 6.699564e-05 8.345130e-05 5.241794e-05 #> SMI  6.699564e-05 8.556317e-05 6.285881e-05 4.304517e-05 #> CAC  8.345130e-05 6.285881e-05 1.216802e-04 5.693174e-05 #> FTSE 5.241794e-05 4.304517e-05 5.693174e-05 6.332543e-05"},{"path":"/reference/fit_to_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Double-Decay Covariance Matrix by Entropy-Pooling — fit_to_moments","title":"Double-Decay Covariance Matrix by Entropy-Pooling — fit_to_moments","text":"Internal function computes flexible probabilities given double-decay covariance matrix.","code":""},{"path":"/reference/fit_to_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Double-Decay Covariance Matrix by Entropy-Pooling — fit_to_moments","text":"","code":"fit_to_moments(X, m, S)"},{"path":"/reference/fit_to_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Double-Decay Covariance Matrix by Entropy-Pooling — fit_to_moments","text":"X matrix size TxN relevant risk drivers. m matrix size Nx1 given Double_Decay risk drivers location. S matrix size NxN given Double_Decay dispersion matrix risk drivers.","code":""},{"path":"/reference/fit_to_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Double-Decay Covariance Matrix by Entropy-Pooling — fit_to_moments","text":"matrix vector posterior probabilities.","code":""},{"path":"/reference/half_life.html","id":null,"dir":"Reference","previous_headings":"","what":"Half-Life Calculation — half_life","title":"Half-Life Calculation — half_life","text":"Compute implied half-life decay parameter.","code":""},{"path":"/reference/half_life.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Half-Life Calculation — half_life","text":"","code":"half_life(lambda)"},{"path":"/reference/half_life.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Half-Life Calculation — half_life","text":"lambda number.","code":""},{"path":"/reference/half_life.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Half-Life Calculation — half_life","text":"single number half-life days.","code":""},{"path":[]},{"path":"/reference/half_life.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Half-Life Calculation — half_life","text":"","code":"half_life(0.0166) #> [1] 42 half_life(0.01) #> [1] 69"},{"path":"/reference/kernel_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Information Kernel-Damping — kernel_entropy","title":"Partial Information Kernel-Damping — kernel_entropy","text":"Find probability distribution can constrain first two moments imposing minimal structure data.","code":""},{"path":"/reference/kernel_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Information Kernel-Damping — kernel_entropy","text":"","code":"kernel_entropy(x, mean, sigma = NULL)  # S3 method for default kernel_entropy(x, mean, sigma = NULL)  # S3 method for numeric kernel_entropy(x, mean, sigma = NULL)  # S3 method for matrix kernel_entropy(x, mean, sigma = NULL)  # S3 method for ts kernel_entropy(x, mean, sigma = NULL)  # S3 method for xts kernel_entropy(x, mean, sigma = NULL)  # S3 method for tbl_df kernel_entropy(x, mean, sigma = NULL)  # S3 method for data.frame kernel_entropy(x, mean, sigma = NULL)"},{"path":"/reference/kernel_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Information Kernel-Damping — kernel_entropy","text":"x univariate multivariate distribution. mean numeric vector kernel centered. sigma uncertainty (volatility) around mean. NULL, mean constrained.","code":""},{"path":"/reference/kernel_entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Information Kernel-Damping — kernel_entropy","text":"numerical vector class ffp new probabilities distribution.","code":""},{"path":[]},{"path":"/reference/kernel_entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Information Kernel-Damping — kernel_entropy","text":"","code":"library(ggplot2)  ret <- diff(log(EuStockMarkets[ , 1])) mean <- -0.01 # scenarios around -1% sigma <- var(diff(ret))  ke <- kernel_entropy(ret, mean, sigma) ke #> <ffp[1859]> #> 0.0009255605 0.000599916 0.0001537338 0.0004681907 0.000614085 ... 3.258238e-05  autoplot(ke) +   scale_color_viridis_c()"},{"path":"/reference/kernel_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Full Information by Kernel-Damping — kernel_normal","title":"Full Information by Kernel-Damping — kernel_normal","text":"Historical realizations receive weight proportional distance target mean.","code":""},{"path":"/reference/kernel_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full Information by Kernel-Damping — kernel_normal","text":"","code":"kernel_normal(x, mean, sigma)  # S3 method for default kernel_normal(x, mean, sigma)  # S3 method for numeric kernel_normal(x, mean, sigma)  # S3 method for matrix kernel_normal(x, mean, sigma)  # S3 method for ts kernel_normal(x, mean, sigma)  # S3 method for xts kernel_normal(x, mean, sigma)  # S3 method for tbl_df kernel_normal(x, mean, sigma)  # S3 method for data.frame kernel_normal(x, mean, sigma)"},{"path":"/reference/kernel_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full Information by Kernel-Damping — kernel_normal","text":"x univariate multivariate distribution. mean numeric vector kernel centered. sigma uncertainty (volatility) around mean.","code":""},{"path":"/reference/kernel_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full Information by Kernel-Damping — kernel_normal","text":"numerical vector class ffp new probabilities distribution.","code":""},{"path":[]},{"path":"/reference/kernel_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full Information by Kernel-Damping — kernel_normal","text":"","code":"library(ggplot2)  ret <- diff(log(EuStockMarkets[ , 1])) mean <- -0.01 # scenarios around -1% sigma <- var(diff(ret))  kn <- kernel_normal(ret, mean, sigma) kn #> <ffp[1859]> #> 0.0007806016 0.0007261808 0.0003335773 0.0006663388 0.0007309458 ... 7.07516e-05  autoplot(kn) +   scale_color_viridis_c()   # A larger sigma spreads out the distribution sigma <- var(diff(ret)) / 0.05 kn <- kernel_normal(ret, mean, sigma)  autoplot(kn) +   scale_color_viridis_c()"},{"path":"/reference/least_info_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Information Kernel-Smoothing — least_info_kernel","title":"Least Information Kernel-Smoothing — least_info_kernel","text":"internal function uses kernel-smoothing approach compute posterior probabilities satisfies macroeconomic statement.","code":""},{"path":"/reference/least_info_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Information Kernel-Smoothing — least_info_kernel","text":"","code":"least_info_kernel(Y, y, h2)"},{"path":"/reference/least_info_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Information Kernel-Smoothing — least_info_kernel","text":"Y matrix macroeconomic indicators. y numeric scalar target Y expected near . h2 matrix covariance Y factor.","code":""},{"path":"/reference/least_info_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Information Kernel-Smoothing — least_info_kernel","text":"vector new probability distribution.","code":""},{"path":"/reference/relative_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Relative Entropy — relative_entropy","title":"Relative Entropy — relative_entropy","text":"Computes relative entropy two distributions.","code":""},{"path":"/reference/relative_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relative Entropy — relative_entropy","text":"","code":"relative_entropy(prior, posterior)"},{"path":"/reference/relative_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relative Entropy — relative_entropy","text":"prior prior probability distribution. posterior posterior probability distribution.","code":""},{"path":"/reference/relative_entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relative Entropy — relative_entropy","text":"double relative entropy.","code":""},{"path":"/reference/relative_entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Relative Entropy — relative_entropy","text":"","code":"set.seed(222)  prior <- rep(1 / 100, 100)  posterior <- runif(100) posterior <- posterior / sum(posterior)  relative_entropy(prior, posterior) #> [1] 0.2074987"},{"path":"/reference/scenario_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Scenarios — scenario_density","title":"Plot Scenarios — scenario_density","text":"functions designed make easier visualize impact View P&L distribution.","code":""},{"path":"/reference/scenario_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Scenarios — scenario_density","text":"","code":"scenario_density(x, p, n = 10000)  scenario_histogram(x, p, n = 10000)"},{"path":"/reference/scenario_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Scenarios — scenario_density","text":"x univariate marginal distribution. p probability ffp class. n integer scalar number scenarios generated.","code":""},{"path":"/reference/scenario_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Scenarios — scenario_density","text":"ggplot2 object.","code":""},{"path":"/reference/scenario_density.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Scenarios — scenario_density","text":"generate scenario-distribution margins bootstrapped using bootstrap_scenarios. number resamples can controlled n argument (default n = 10000).","code":""},{"path":"/reference/scenario_density.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Scenarios — scenario_density","text":"","code":"x <- diff(log(EuStockMarkets))[, 1] p <- exp_decay(x, 0.005)  scenario_density(x, p, 500)   scenario_histogram(x, p, 500)"},{"path":"/reference/view_on_copula.html","id":null,"dir":"Reference","previous_headings":"","what":"Views on Copulas — view_on_copula","title":"Views on Copulas — view_on_copula","text":"Helper construct constraints copulas entropy programming.","code":""},{"path":"/reference/view_on_copula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Views on Copulas — view_on_copula","text":"","code":"view_on_copula(x, simul, p)  # S3 method for default view_on_copula(x, simul, p)  # S3 method for matrix view_on_copula(x, simul, p)  # S3 method for xts view_on_copula(x, simul, p)  # S3 method for tbl_df view_on_copula(x, simul, p)"},{"path":"/reference/view_on_copula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Views on Copulas — view_on_copula","text":"x multivariate copula. simul simulated target copula. p object ffp class.","code":""},{"path":"/reference/view_on_copula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Views on Copulas — view_on_copula","text":"list view class.","code":""},{"path":"/reference/view_on_copula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Views on Copulas — view_on_copula","text":"","code":"# \\donttest{   set.seed(1)   library(ggplot2)    # Invariants   ret <- diff(log(EuStockMarkets))   u <- apply(ret, 2, stats::pnorm) # assuming normal copula   n <- nrow(u)    #' Prior probability distribution   prior <- rep(1 / n, n)    # Simulated marginals   simul_marg <- bootstrap_scenarios(ret, as_ffp(prior), as.double(n))    # Copulas derived from the simulated margins   simul_cop <- apply(simul_marg, 2, stats::pnorm) # assuming normal copula    views <- view_on_copula(x = u, simul = simul_cop, p = prior)   views #> # ffp view #> Type:  View On Copula #> Aeq :  Dim 34 x 1859  #> beq :  Dim 34 x 1     ep <- entropy_pooling(p = prior, Aeq = views$Aeq, beq = views$beq, solver = \"nloptr\")   autoplot(ep)  # }"},{"path":"/reference/view_on_correlation.html","id":null,"dir":"Reference","previous_headings":"","what":"Views on Correlation Structure — view_on_correlation","title":"Views on Correlation Structure — view_on_correlation","text":"Helper construct views  correlation matrix.","code":""},{"path":"/reference/view_on_correlation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Views on Correlation Structure — view_on_correlation","text":"","code":"view_on_correlation(x, cor)  # S3 method for default view_on_correlation(x, cor)  # S3 method for matrix view_on_correlation(x, cor)  # S3 method for xts view_on_correlation(x, cor)  # S3 method for tbl_df view_on_correlation(x, cor)"},{"path":"/reference/view_on_correlation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Views on Correlation Structure — view_on_correlation","text":"x univariate multivariate distribution. cor matrix target correlation structure series x.","code":""},{"path":"/reference/view_on_correlation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Views on Correlation Structure — view_on_correlation","text":"list view class.","code":""},{"path":"/reference/view_on_correlation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Views on Correlation Structure — view_on_correlation","text":"","code":"library(ggplot2)  # Invariant ret <- diff(log(EuStockMarkets))  # Assume that a panic event throws all correlations to the roof! co <- matrix(0.95, 4, 4) diag(co) <- 1 co #>      [,1] [,2] [,3] [,4] #> [1,] 1.00 0.95 0.95 0.95 #> [2,] 0.95 1.00 0.95 0.95 #> [3,] 0.95 0.95 1.00 0.95 #> [4,] 0.95 0.95 0.95 1.00  # Prior probability (usually the equal-weight setting) prior <- rep(1 / nrow(ret), nrow(ret))  # View views <- view_on_correlation(x = ret, cor = co) views #> # ffp view #> Type:  View On Correlation #> Aeq :  Dim 10 x 1859  #> beq :  Dim 10 x 1   # Optimization ep <- entropy_pooling(p = prior, Aeq = views$Aeq, beq = views$beq, solver = \"nlminb\") autoplot(ep)   # prior correlation structure stats::cor(ret) #>            DAX       SMI       CAC      FTSE #> DAX  1.0000000 0.7031219 0.7344304 0.6394674 #> SMI  0.7031219 1.0000000 0.6160454 0.5847791 #> CAC  0.7344304 0.6160454 1.0000000 0.6485679 #> FTSE 0.6394674 0.5847791 0.6485679 1.0000000  # posterior correlation structure matches the initial view very closely stats::cov2cor(ffp_moments(x = ret, p = ep)$sigma) #>            DAX       SMI       CAC      FTSE #> DAX  1.0000000 0.9509531 0.9538418 0.9494368 #> SMI  0.9509531 1.0000000 0.9518980 0.9426105 #> CAC  0.9538418 0.9518980 1.0000000 0.9447604 #> FTSE 0.9494368 0.9426105 0.9447604 1.0000000"},{"path":"/reference/view_on_covariance.html","id":null,"dir":"Reference","previous_headings":"","what":"Views on Covariance Matrix — view_on_covariance","title":"Views on Covariance Matrix — view_on_covariance","text":"Helper construct views variance-covariance matrix.","code":""},{"path":"/reference/view_on_covariance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Views on Covariance Matrix — view_on_covariance","text":"","code":"view_on_covariance(x, mean, sigma)  # S3 method for default view_on_covariance(x, mean, sigma)  # S3 method for matrix view_on_covariance(x, mean, sigma)  # S3 method for xts view_on_covariance(x, mean, sigma)  # S3 method for tbl_df view_on_covariance(x, mean, sigma)"},{"path":"/reference/view_on_covariance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Views on Covariance Matrix — view_on_covariance","text":"x univariate multivariate distribution. mean double location parameter series x. sigma matrix target variance-covariance parameter series x.","code":""},{"path":"/reference/view_on_covariance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Views on Covariance Matrix — view_on_covariance","text":"list view class.","code":""},{"path":"/reference/view_on_covariance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Views on Covariance Matrix — view_on_covariance","text":"","code":"library(ggplot2)  # Invariant (stationarity) ret <- diff(log(EuStockMarkets))  # Expectations for location and dispersion parameters mean <- colMeans(ret) # No active expectations for returns cor <- matrix(0, ncol = 4, nrow = 4) # diagonal covariance matrix diag(cor) <- 1                       # diagonal covariance matrix sds <- apply(ret, 2, sd)             # diagonal covariance matrix covs <- diag(sds) %*% cor %*% diag(sds) ## diagonal covariance matrix  # prior probabilities (usually equal weight scheme) prior <- rep(1 / nrow(ret), nrow(ret))  # Views views <- view_on_covariance(x = ret, mean = mean, sigma = covs) views #> # ffp view #> Type:  View On Covariance #> Aeq :  Dim 10 x 1859  #> beq :  Dim 10 x 1   # Optimization ep <- entropy_pooling(p = prior, Aeq = views$Aeq, beq = views$beq, solver = \"nlminb\") autoplot(ep)   # original covariance matrix stats::cov(ret) #>               DAX          SMI          CAC         FTSE #> DAX  1.061072e-04 6.699564e-05 8.345130e-05 5.241794e-05 #> SMI  6.699564e-05 8.556317e-05 6.285881e-05 4.304517e-05 #> CAC  8.345130e-05 6.285881e-05 1.216802e-04 5.693174e-05 #> FTSE 5.241794e-05 4.304517e-05 5.693174e-05 6.332543e-05  # Posterior covariance matrix ffp_moments(x = ret, p = ep)$sigma #>                DAX           SMI          CAC          FTSE #> DAX   1.034982e-04 -9.807377e-07 5.084087e-06 -3.943374e-06 #> SMI  -9.807377e-07  8.375999e-05 1.339814e-06 -1.440063e-06 #> CAC   5.084087e-06  1.339814e-06 1.204302e-04  9.662796e-07 #> FTSE -3.943374e-06 -1.440063e-06 9.662796e-07  6.224202e-05"},{"path":"/reference/view_on_joint_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Views on Joint Distribution — view_on_joint_distribution","title":"Views on Joint Distribution — view_on_joint_distribution","text":"Helper construct constraints entire distribution.","code":""},{"path":"/reference/view_on_joint_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Views on Joint Distribution — view_on_joint_distribution","text":"","code":"view_on_joint_distribution(x, simul, p)  # S3 method for default view_on_joint_distribution(x, simul, p)  # S3 method for matrix view_on_joint_distribution(x, simul, p)  # S3 method for xts view_on_joint_distribution(x, simul, p)  # S3 method for tbl_df view_on_joint_distribution(x, simul, p)"},{"path":"/reference/view_on_joint_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Views on Joint Distribution — view_on_joint_distribution","text":"x univariate multivariate distribution. simul univariate multivariate simulated panel. p object ffp class.","code":""},{"path":"/reference/view_on_joint_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Views on Joint Distribution — view_on_joint_distribution","text":"list view class.","code":""},{"path":"/reference/view_on_joint_distribution.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Views on Joint Distribution — view_on_joint_distribution","text":"simul must number columns x p number rows simul.","code":""},{"path":"/reference/view_on_joint_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Views on Joint Distribution — view_on_joint_distribution","text":"","code":"set.seed(1) library(ggplot2)  # Invariants ret <- diff(log(EuStockMarkets)) n <- nrow(ret)  #' Prior probability distribution prior <- rep(1 / n, n)  # Simulated marginals simul <- bootstrap_scenarios(ret, as_ffp(prior), as.double(n))  views <- view_on_joint_distribution(x = ret, simul = simul, p = prior) views #> # ffp view #> Type:  View On Joint Distribution #> Aeq :  Dim 14 x 1859  #> beq :  Dim 14 x 1   ep <- entropy_pooling(p = prior, Aeq = views$Aeq, beq = views$beq, solver = \"nlminb\") autoplot(ep)   # location matches colMeans(simul) #>           DAX           SMI           CAC          FTSE  #>  0.0002882227  0.0005169526 -0.0001995663  0.0001186610  ffp_moments(x = ret, p = ep)$mu #>           DAX           SMI           CAC          FTSE  #>  0.0002862887  0.0005163121 -0.0002013750  0.0001175073   # dispersion matches cov(simul) #>               DAX          SMI          CAC         FTSE #> DAX  1.073869e-04 7.191219e-05 8.163091e-05 5.193336e-05 #> SMI  7.191219e-05 9.252845e-05 6.601878e-05 4.387011e-05 #> CAC  8.163091e-05 6.601878e-05 1.191442e-04 5.479092e-05 #> FTSE 5.193336e-05 4.387011e-05 5.479092e-05 6.188198e-05 ffp_moments(x = ret, p = ep)$sigma #>               DAX          SMI          CAC         FTSE #> DAX  1.074705e-04 7.205167e-05 8.176366e-05 5.131337e-05 #> SMI  7.205167e-05 9.235423e-05 6.598208e-05 4.403098e-05 #> CAC  8.176366e-05 6.598208e-05 1.196482e-04 5.440638e-05 #> FTSE 5.131337e-05 4.403098e-05 5.440638e-05 6.150596e-05"},{"path":"/reference/view_on_marginal_distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Views on Marginal Distribution — view_on_marginal_distribution","title":"Views on Marginal Distribution — view_on_marginal_distribution","text":"Helper construct constraints marginal distribution.","code":""},{"path":"/reference/view_on_marginal_distribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Views on Marginal Distribution — view_on_marginal_distribution","text":"","code":"view_on_marginal_distribution(x, simul, p)  # S3 method for default view_on_marginal_distribution(x, simul, p)  # S3 method for matrix view_on_marginal_distribution(x, simul, p)  # S3 method for xts view_on_marginal_distribution(x, simul, p)  # S3 method for tbl_df view_on_marginal_distribution(x, simul, p)"},{"path":"/reference/view_on_marginal_distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Views on Marginal Distribution — view_on_marginal_distribution","text":"x univariate multivariate distribution. simul univariate multivariate simulated panel. p object ffp class.","code":""},{"path":"/reference/view_on_marginal_distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Views on Marginal Distribution — view_on_marginal_distribution","text":"list view class.","code":""},{"path":"/reference/view_on_marginal_distribution.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Views on Marginal Distribution — view_on_marginal_distribution","text":"simul must number columns x p number rows simul.","code":""},{"path":"/reference/view_on_marginal_distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Views on Marginal Distribution — view_on_marginal_distribution","text":"","code":"set.seed(1) library(ggplot2)  # Invariants ret <- diff(log(EuStockMarkets)) n <- nrow(ret)  #' Prior probability distribution prior <- rep(1 / n, n)  # Simulated marginals simul <- bootstrap_scenarios(ret, as_ffp(prior), as.double(n))  views <- view_on_marginal_distribution(x = ret, simul = simul, p = prior) views #> # ffp view #> Type:  View On Marginal Distribution #> Aeq :  Dim 8 x 1859  #> beq :  Dim 8 x 1   ep <- entropy_pooling(p = prior, Aeq = views$Aeq, beq = views$beq, solver = \"nlminb\") autoplot(ep)   # location matches colMeans(simul) #>           DAX           SMI           CAC          FTSE  #>  0.0002882227  0.0005169526 -0.0001995663  0.0001186610  ffp_moments(x = ret, p = ep)$mu #>           DAX           SMI           CAC          FTSE  #>  0.0002882228  0.0005169526 -0.0001995663  0.0001186609   # dispersion matches cov(simul) #>               DAX          SMI          CAC         FTSE #> DAX  1.073869e-04 7.191219e-05 8.163091e-05 5.193336e-05 #> SMI  7.191219e-05 9.252845e-05 6.601878e-05 4.387011e-05 #> CAC  8.163091e-05 6.601878e-05 1.191442e-04 5.479092e-05 #> FTSE 5.193336e-05 4.387011e-05 5.479092e-05 6.188198e-05 ffp_moments(x = ret, p = ep)$sigma #>               DAX          SMI          CAC         FTSE #> DAX  1.073792e-04 7.070163e-05 8.346904e-05 5.239964e-05 #> SMI  7.070163e-05 9.253669e-05 6.508528e-05 4.444309e-05 #> CAC  8.346904e-05 6.508528e-05 1.191358e-04 5.574772e-05 #> FTSE 5.239964e-05 4.444309e-05 5.574772e-05 6.192666e-05"},{"path":"/reference/view_on_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Views on Expected Returns — view_on_mean","title":"Views on Expected Returns — view_on_mean","text":"Helper construct views expected returns.","code":""},{"path":"/reference/view_on_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Views on Expected Returns — view_on_mean","text":"","code":"view_on_mean(x, mean)  # S3 method for default view_on_mean(x, mean)  # S3 method for matrix view_on_mean(x, mean)  # S3 method for xts view_on_mean(x, mean)  # S3 method for tbl_df view_on_mean(x, mean)"},{"path":"/reference/view_on_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Views on Expected Returns — view_on_mean","text":"x univariate multivariate distribution. mean double target location parameter series x.","code":""},{"path":"/reference/view_on_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Views on Expected Returns — view_on_mean","text":"list view class.","code":""},{"path":"/reference/view_on_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Views on Expected Returns — view_on_mean","text":"","code":"library(ggplot2)  # Invariant ret <- diff(log(EuStockMarkets)) n   <- nrow(ret)  # View on expected returns (here is 2% for each asset) mean <- rep(0.02, 4)  # Prior probabilities (usually equal weight scheme) prior <- rep(1 / n, n)  # View views <- view_on_mean(x = ret, mean = mean) views #> # ffp view #> Type:  View On Mean #> Aeq :  Dim 4 x 1859  #> beq :  Dim 4 x 1   # Optimization ep <- entropy_pooling(p = prior, Aeq = views$Aeq, beq = views$beq, solver = \"nlminb\") autoplot(ep)   # Probabilities are twisted in such a way that the posterior # `mu` match's exactly with previously stated beliefs ffp_moments(x = ret, p = ep)$mu #>        DAX        SMI        CAC       FTSE  #> 0.02000001 0.02000001 0.02000000 0.02000000"},{"path":"/reference/view_on_rank.html","id":null,"dir":"Reference","previous_headings":"","what":"Views on Relative Performance — view_on_rank","title":"Views on Relative Performance — view_on_rank","text":"Helper construct views relative performance assets.","code":""},{"path":"/reference/view_on_rank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Views on Relative Performance — view_on_rank","text":"","code":"view_on_rank(x, rank)  # S3 method for default view_on_rank(x, rank)  # S3 method for matrix view_on_rank(x, rank)  # S3 method for xts view_on_rank(x, rank)  # S3 method for tbl_df view_on_rank(x, rank)"},{"path":"/reference/view_on_rank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Views on Relative Performance — view_on_rank","text":"x univariate multivariate distribution. rank integer assets rank (worst best performer).","code":""},{"path":"/reference/view_on_rank.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Views on Relative Performance — view_on_rank","text":"list view class.","code":""},{"path":"/reference/view_on_rank.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Views on Relative Performance — view_on_rank","text":"rank = c(2, 1) implied asset first column outperform asset second column. longer vectors interpretation : assets right outperform assets left.","code":""},{"path":"/reference/view_on_rank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Views on Relative Performance — view_on_rank","text":"","code":"library(ggplot2)  # Invariants x <- diff(log(EuStockMarkets)) prior <- rep(1 / nrow(x), nrow(x))  # asset in the first col will outperform the asset in the second col (DAX will # outperform SMI). views <- view_on_rank(x = x, rank = c(2, 1)) views #> # ffp view #> Type:  View On Rank #> A :  Dim 1 x 1859  #> b :  Dim 1 x 1   ep <- entropy_pooling(p = prior, A = views$A, b = views$b, solver = \"nloptr\") autoplot(ep)   # Prior Returns (SMI > DAX) colMeans(x)[1:2] #>          DAX          SMI  #> 0.0006520417 0.0008178997   # Posterior Returns (DAX > SMI) ffp_moments(x, ep)$mu[1:2] #>          DAX          SMI  #> 0.0007646772 0.0007646772"},{"path":"/reference/view_on_volatility.html","id":null,"dir":"Reference","previous_headings":"","what":"Views on Volatility — view_on_volatility","title":"Views on Volatility — view_on_volatility","text":"Helper construct views volatility.","code":""},{"path":"/reference/view_on_volatility.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Views on Volatility — view_on_volatility","text":"","code":"view_on_volatility(x, vol)  # S3 method for default view_on_volatility(x, vol)  # S3 method for matrix view_on_volatility(x, vol)  # S3 method for xts view_on_volatility(x, vol)  # S3 method for tbl_df view_on_volatility(x, vol)"},{"path":"/reference/view_on_volatility.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Views on Volatility — view_on_volatility","text":"x univariate multivariate distribution. vol double target volatility structure series x.","code":""},{"path":"/reference/view_on_volatility.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Views on Volatility — view_on_volatility","text":"list view class.","code":""},{"path":"/reference/view_on_volatility.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Views on Volatility — view_on_volatility","text":"","code":"library(ggplot2)  # Invariant ret <- diff(log(EuStockMarkets)) n   <- nrow(ret)  # Expected a volatility 30% higher than historical average vol <- apply(ret, 2, stats::sd) * 1.3  # Prior Probabilities prior <- rep(1 / n, n)  # Views views <- view_on_volatility(x = ret, vol = vol) views #> # ffp view #> Type:  View On Volatility #> Aeq :  Dim 4 x 1859  #> beq :  Dim 4 x 1   # Optimization ep <- entropy_pooling(p = prior, Aeq = views$Aeq, beq = views$beq, solver = \"nlminb\") autoplot(ep)   # Desired volatility vol #>        DAX        SMI        CAC       FTSE  #> 0.01339109 0.01202505 0.01434014 0.01034505   # Posterior volatility matches very closely with the desired volatility sqrt(diag(ffp_moments(x = ret, p = ep)$sigma)) #>        DAX        SMI        CAC       FTSE  #> 0.01341064 0.01204973 0.01434835 0.01033864"},{"path":"/news/index.html","id":"ffp-021","dir":"Changelog","previous_headings":"","what":"ffp 0.2.1","title":"ffp 0.2.1","text":"CRAN release: 2022-03-24 Bug fix entropy_pooling() dealing multiple inequalities constraints; Small changes documentation files.","code":""},{"path":"/news/index.html","id":"ffp-020","dir":"Changelog","previous_headings":"","what":"ffp 0.2.0","title":"ffp 0.2.0","text":"CRAN release: 2022-02-17","code":""},{"path":"/news/index.html","id":"new-features-0-2-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"ffp 0.2.0","text":"new class (ffp_views) added help user input views market portfolio construction simulation purposes. See view_*() family functions; entropy_pooling() now exported can used three different solvers (nlminb, solnl, nloptr); bind_views() allows user “glue” multiple views object; ffp_moments() computes location dispersion parameters flexible probabilities.","code":""},{"path":"/news/index.html","id":"minor-improvements-and-fixes-0-2-0","dir":"Changelog","previous_headings":"","what":"Minor improvements and fixes","title":"ffp 0.2.0","text":"bind_probs() now returns user call third column instead old arbitrary key column (#13);","code":""},{"path":[]},{"path":"/news/index.html","id":"ffp-010","dir":"Changelog","previous_headings":"","what":"ffp 0.1.0","title":"ffp 0.1.0","text":"CRAN release: 2021-07-14 CRAN release.","code":""},{"path":"/news/index.html","id":"ffp-001","dir":"Changelog","previous_headings":"","what":"ffp 0.0.1","title":"ffp 0.0.1","text":"package now built upon S3 vctrs, instead tibbles; Functions bootstrap_scenarios(), scenario_density() bind_probs() accepts objects ffp class; Added ffp method ggplot2::autoplot(); Exponential Smoothing now computed exp_decay().","code":""},{"path":"/news/index.html","id":"ffp-009000","dir":"Changelog","previous_headings":"","what":"ffp 0.0.9000","title":"ffp 0.0.9000","text":"First release development version ffp.","code":""}]
